# -*- coding: utf-8 -*-
"""Solar_Power_prediction_LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pRlFH50mpA-EvAjvp--gQUP9O-3MLzgE
"""

import random
import tensorflow as tf
import pickle
import sklearn 
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn import preprocessing
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


data = pd.read_csv("Solardatanew.csv")
data.head(5)

waste_1 = data.pop('Timestamp')

data.info()

min_d = data['Power_Generated'].min()

max_d = data['Power_Generated'].max()

data["Power_Generated"].describe()

sns.scatterplot(x="Solar_Radiation", y="Relative_Humidity",
                hue="Power_Generated",
                sizes=(3, 15), linewidth=0,
                data=data)

sns.jointplot(x='Power_Generated', y='Relative_Humidity',
              data=data, kind='kde', color='brown')

sns.jointplot(x='Solar_Radiation', y='Relative_Humidity',
              data=data, kind='kde', color='green')

data.info()

scaler = MinMaxScaler()

names = ["Air_Temp", "Relative_Humidity", "Solar_Radiation",
         "RTD", "Array_Voltage", "Array_Current", "Power_Generated"]
data[names] = scaler.fit_transform(data[names])

X = data
Y = data.pop("Power_Generated")

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)

X.head(10)

Y.head()

X.shape

# Commented out IPython magic to ensure Python compatibility.

tf.random.set_seed(42)

model_2 = tf.keras.Sequential([tf.keras.layers.LSTM(300, activation='relu', return_sequences=True, input_shape=(6, 1)),
                               tf.keras.layers.Dropout(0.2, seed=42),
                               tf.keras.layers.LSTM(
    200, activation='relu'),
    tf.keras.layers.Dropout(0.2, seed=42),
    tf.keras.layers.Dense(1)])

model_2.compile(loss='mae',
                optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),
                metrics=['mae'])

history_2 = model_2.fit(tf.expand_dims(
    X_train, axis=-1), Y_train, epochs=15)

model_2.evaluate(X_test, Y_test)

pd.DataFrame(history_2.history).plot()
plt.title("Error")
plt.xlabel("Epochs")
plt.ylabel("Mean Absoulte Error")

pred_2 = model_2.predict(Y_test)

pred_2.shape

pred_2

normalized_d = pred_2

final_power = normalized_d * (max_d - min_d) + min_d

final_power

final_power.shape


